{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Data Extraction from Wikidata\n",
    "\n",
    "This notebook extracts human rights defenders data from Wikidata and enriches it with works counts.\n",
    "\n",
    "## Steps\n",
    "1. Load raw human rights defender data\n",
    "2. Clean and standardize country names\n",
    "3. Fetch works counts from Wikidata API\n",
    "4. Save processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/human_rights_defender.csv')\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Cleaning\n",
    "\n",
    "### 2.1 Parse dates and calculate productive year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date columns\n",
    "df['birthDate'] = pd.to_datetime(df['birthDate'], errors='coerce')\n",
    "df['deathDate'] = pd.to_datetime(df['deathDate'], errors='coerce')\n",
    "\n",
    "# Calculate productive year (birth + 35 years, or death - 35 years)\n",
    "df['productive_year'] = df.apply(\n",
    "    lambda row: row['birthYear'] + 35 if pd.notna(row['birthYear']) \n",
    "                else row['deathYear'] - 35 if pd.notna(row['deathYear']) \n",
    "                else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Productive year range: {df['productive_year'].min():.0f} - {df['productive_year'].max():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Standardize country names\n",
    "\n",
    "Map historical countries to modern equivalents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNTRY_MAPPING = {\n",
    "    'Kingdom of England': 'United Kingdom',\n",
    "    'Kingdom of France': 'France',\n",
    "    'West Germany': 'Germany',\n",
    "    'Soviet Union': 'Russia',\n",
    "    'Republic of Vietnam': 'Vietnam',\n",
    "    'Czechoslovakia': 'Czech Republic',\n",
    "    'Tibet Autonomous Region': 'China',\n",
    "    \"People's Republic of China\": 'China',\n",
    "    'Hong Kong': 'China',\n",
    "    'British Raj': 'India',\n",
    "    'British Hong Kong': 'China',\n",
    "    'Ottoman Empire': 'Turkey',\n",
    "    'Kingdom of Romania': 'Romania',\n",
    "    'Russian Empire': 'Russia',\n",
    "    'Austrian Empire': 'Austria',\n",
    "    'Austria-Hungary': 'Austria',\n",
    "    'Weimar Republic': 'Germany',\n",
    "    'German Democratic Republic': 'Germany',\n",
    "    'Kingdom of Italy': 'Italy',\n",
    "    'Empire of Japan': 'Japan',\n",
    "    'Qing dynasty': 'China',\n",
    "    'French protectorate of Tunisia': 'Tunisia',\n",
    "    'Kingdom of Great Britain': 'United Kingdom',\n",
    "    'United Kingdom of Great Britain and Ireland': 'United Kingdom',\n",
    "    'statelessness': None,\n",
    "    'Yugoslavia': 'Serbia',\n",
    "    'Socialist Federal Republic of Yugoslavia': 'Serbia',\n",
    "    'Federal Republic of Yugoslavia': 'Serbia',\n",
    "    'Serbia and Montenegro': 'Serbia',\n",
    "}\n",
    "\n",
    "df['modern_country'] = df['citizenshipLabel'].replace(COUNTRY_MAPPING)\n",
    "df['modern_country'] = df['modern_country'].fillna(df['citizenshipLabel'])\n",
    "\n",
    "print(f\"Unique countries: {df['modern_country'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Fetch Works Counts from Wikidata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_works_count_batch(entity_ids):\n",
    "    \"\"\"\n",
    "    Get the number of works for multiple Wikidata entities in a single query.\n",
    "    \n",
    "    Args:\n",
    "        entity_ids: List of Wikidata IDs like ['Q557', 'Q4715', ...]\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary mapping entity_id to count of works\n",
    "    \"\"\"\n",
    "    values_clause = \" \".join([f\"wd:{eid}\" for eid in entity_ids])\n",
    "    \n",
    "    sparql_query = f\"\"\"\n",
    "    SELECT ?person (COUNT(DISTINCT ?work) as ?count) WHERE {{\n",
    "      VALUES ?person {{ {values_clause} }}\n",
    "      {{\n",
    "        ?work wdt:P50 ?person .  # author\n",
    "      }} UNION {{\n",
    "        ?work wdt:P170 ?person . # creator\n",
    "      }} UNION {{\n",
    "        ?work wdt:P655 ?person . # translator\n",
    "      }} UNION {{\n",
    "        ?work wdt:P86 ?person .  # composer\n",
    "      }} UNION {{\n",
    "        ?work wdt:P57 ?person .  # director\n",
    "      }} UNION {{\n",
    "        ?work wdt:P58 ?person .  # screenwriter\n",
    "      }} UNION {{\n",
    "        ?work wdt:P161 ?person . # cast member\n",
    "      }} UNION {{\n",
    "        ?work wdt:P800 ?person . # notable work\n",
    "      }}\n",
    "    }}\n",
    "    GROUP BY ?person\n",
    "    \"\"\"\n",
    "    \n",
    "    endpoint_url = \"https://query.wikidata.org/sparql\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (compatible; HumanRightsResearch/1.0)',\n",
    "        'Accept': 'application/sparql-results+json'\n",
    "    }\n",
    "    params = {'query': sparql_query, 'format': 'json'}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(endpoint_url, params=params, headers=headers, timeout=60)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        results = {eid: 0 for eid in entity_ids}\n",
    "        \n",
    "        if 'results' in data and 'bindings' in data['results']:\n",
    "            for binding in data['results']['bindings']:\n",
    "                person_uri = binding['person']['value']\n",
    "                entity_id = person_uri.split('/')[-1]\n",
    "                count = int(binding['count']['value'])\n",
    "                results[entity_id] = count\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return {eid: None for eid in entity_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract entity IDs\n",
    "df['entity_id'] = df['person'].str.extract(r'/(Q\\d+)$')[0]\n",
    "valid_entities = df[df['entity_id'].notna()]['entity_id'].unique().tolist()\n",
    "\n",
    "print(f\"Processing {len(valid_entities)} unique entities...\")\n",
    "\n",
    "# Fetch in batches\n",
    "batch_size = 50\n",
    "all_results = {}\n",
    "\n",
    "for i in tqdm(range(0, len(valid_entities), batch_size), desc=\"Fetching works counts\"):\n",
    "    batch = valid_entities[i:i + batch_size]\n",
    "    batch_results = get_wikidata_works_count_batch(batch)\n",
    "    all_results.update(batch_results)\n",
    "    time.sleep(1)  # Rate limiting\n",
    "\n",
    "df['works_count'] = df['entity_id'].map(all_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "df.to_csv('../data/human_rights_defender_clean.csv', index=False)\n",
    "print(f\"Saved {len(df)} rows to data/human_rights_defender_clean.csv\")\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"  Total records: {len(df)}\")\n",
    "print(f\"  Unique individuals: {df['person'].nunique()}\")\n",
    "print(f\"  Date range: {df['productive_year'].min():.0f} - {df['productive_year'].max():.0f}\")\n",
    "print(f\"  Countries: {df['modern_country'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
